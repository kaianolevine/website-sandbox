name: Generate pages/pages.json

on:
  push:
    branches:
      - main
      - test-feature
    paths:
      - "pages/**/*.md"
      - ".github/workflows/generate-pages-json.yml"
  workflow_dispatch: {}

permissions:
  contents: write

concurrency:
  group: pages-json-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-manifest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Generate /pages/pages.json
        run: |
          python3 - <<'PY'
          import json
          import re
          from pathlib import Path

          PAGES_DIR = Path("pages")
          OUT_PATH = PAGES_DIR / "pages.json"

          def title_from_slug(slug: str) -> str:
            # "how-it-works" -> "How it works"
            s = slug.replace("_", " ").replace("-", " ").strip()
            return s[:1].upper() + s[1:] if s else slug

          def extract_frontmatter_title(text: str):
            # Very small frontmatter parser:
            # ---
            # title: Something
            # ---
            if not text.startswith("---"):
              return None
            m = re.match(r"^---\s*\n(.*?)\n---\s*\n", text, flags=re.DOTALL)
            if not m:
              return None
            fm = m.group(1)
            # title: ...
            tm = re.search(r"(?m)^\s*title\s*:\s*(.+?)\s*$", fm)
            if not tm:
              return None
            raw = tm.group(1).strip()
            # strip optional quotes
            raw = re.sub(r"^['\"]|['\"]$", "", raw)
            return raw.strip() or None

          def is_md_file(p: Path) -> bool:
            return p.is_file() and p.suffix.lower() == ".md"

          # Collect markdown pages
          md_files = sorted([p for p in PAGES_DIR.rglob("*.md") if is_md_file(p)])

          items = []

          for md in md_files:
            # id maps to /pages/<id>.md, so use path relative to /pages without extension
            rel = md.relative_to(PAGES_DIR).as_posix()
            page_id = rel[:-3]  # drop ".md"

            text = md.read_text(encoding="utf-8", errors="replace")
            title = extract_frontmatter_title(text) or title_from_slug(md.stem)

            items.append({
              "id": page_id,
              "title": title,
            })

          # Load existing pages.json as an ordered reference list (preserve order)
          existing_list = []
          if OUT_PATH.exists():
            try:
              existing_list = json.loads(OUT_PATH.read_text(encoding="utf-8"))
            except Exception:
              existing_list = []

          if not isinstance(existing_list, list):
            existing_list = []

          # Index existing by id, preserving the first occurrence and list order
          existing_by_id = {}
          ordered_existing_ids = []
          for entry in existing_list:
            if not isinstance(entry, dict):
              continue
            pid = entry.get("id")
            if not isinstance(pid, str) or not pid:
              continue
            if pid in existing_by_id:
              continue
            existing_by_id[pid] = entry
            ordered_existing_ids.append(pid)

          # Ensure "home" exists and stays at the beginning
          if "home" not in existing_by_id:
            existing_by_id["home"] = {"id": "home", "title": "Home"}
            ordered_existing_ids.insert(0, "home")
          else:
            # If home exists but is not first, move it to the front
            if ordered_existing_ids and ordered_existing_ids[0] != "home":
              ordered_existing_ids = ["home"] + [pid for pid in ordered_existing_ids if pid != "home"]

          # Build a quick lookup for md-derived titles
          md_title_by_id = {it["id"]: it.get("title") for it in items if isinstance(it, dict) and it.get("id")}

          # Identify markdown pages not referenced in pages.json
          md_ids = [it["id"] for it in items]
          missing_ids = [pid for pid in md_ids if pid not in existing_by_id]

          # Append missing ids in a stable order (path-based)
          missing_ids = sorted(set(missing_ids), key=lambda s: s.lower())

          # Assemble final list: existing entries first (preserving order), then missing entries appended
          final = []

          for pid in ordered_existing_ids:
            entry = dict(existing_by_id[pid])
            # If an existing entry lacks a title, fill from markdown-derived title
            if not entry.get("title") and pid in md_title_by_id and md_title_by_id[pid]:
              entry["title"] = md_title_by_id[pid]
            final.append(entry)

          for pid in missing_ids:
            title = md_title_by_id.get(pid) or title_from_slug(pid.split("/")[-1])
            final.append({"id": pid, "title": title})

          OUT_PATH.parent.mkdir(parents=True, exist_ok=True)
          OUT_PATH.write_text(json.dumps(final, indent=2, ensure_ascii=False) + "\n", encoding="utf-8")
          print(f"Wrote {OUT_PATH} with {len(final)} entries")
          PY

      - name: Commit changes if needed
        run: |
          if git diff --quiet -- pages/pages.json; then
            echo "No changes to commit."
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add pages/pages.json
          git commit -m "chore: regenerate pages/pages.json"
          git push